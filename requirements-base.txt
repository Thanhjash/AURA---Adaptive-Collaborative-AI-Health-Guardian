# Core runtime
fastapi==0.116.1
httpx==0.28.1
uvicorn==0.35.0
python-dotenv==1.1.1
python-multipart==0.0.20

# Firebase & Supabase
firebase_admin==7.0.0
google-generativeai>=0.8.0
supabase==2.17.0

# ML Core
numpy>=1.26,<2.1
scipy>=1.13,<1.15
scikit-learn>=1.4,<2.0
sentence-transformers==5.0.0

# Torch CPU build (safe for server)
torch==2.1.0
torchvision==0.16.0

# Others
pillow==11.3.0
joblib==1.5.1

# llama-cpp for GGUF
llama-cpp-python>=0.2.0 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
