# Core runtime
fastapi==0.116.1
httpx==0.28.1
uvicorn==0.35.0
python-dotenv==1.1.1
python-multipart==0.0.20

# Firebase & Supabase
firebase_admin==7.0.0
google-generativeai>=0.8.0
supabase==2.17.0

# ML Core - FIXED: NumPy 1.x compatible
numpy>=1.21,<2.0
scipy>=1.9,<1.12
scikit-learn>=1.3,<1.5
sentence-transformers==3.3.0

# Torch CPU build (safe for server)
torch==2.1.0
torchvision==0.16.0

# Others
pillow==11.3.0
joblib==1.5.1

# llama-cpp for GGUF
llama-cpp-python>=0.2.0 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
