services:
  ai_server:
    build: ./services/ai_server
    ports:
      - "9000:9000"
    volumes:
      - /mnt/d/3.Project/AURA-Health-Guardian/.hf_cache:/app/.hf_cache
    environment:
      - HF_HOME=/app/.hf_cache
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - aura_network

  ecg_interpreter:
    build: ./services/ecg_interpreter
    ports:
      - "8001:8001"
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - aura_network

  radiology_vqa:
    build: ./services/radiology_vqa
    ports:
      - "8002:8002"
    depends_on:
      - ai_server
    networks:
      - aura_network

  mental_wellness:
    build: ./services/mental_wellness
    ports:
      - "8003:8003"
    depends_on:
      - ai_server
    networks:
      - aura_network

  aura_main:
    build:
      context: .
      dockerfile: services/aura_main/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - ENV=development
    depends_on:
      - ecg_interpreter
      - radiology_vqa 
      - mental_wellness
      - ai_server
    networks:
      - aura_network

networks:
  aura_network:
    driver: bridge